---
title: "matilda-vignette"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{matilda-vignette}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)
```

# Introduction

`matilda` is a package that provides a probabilistic framework to the Hector simple climate model. This package gives the user the capability to randomly generate model parameters from a normal distribution, run Hector using the generated parameters, screen model outputs for realism, and compute probabilities of climate variable projections.

This vignette will work through the basic functionality of `matilda`. First, it shows how to generate a random sample of important model parameters from normal distributions. 
It then shows how to use the newly generated parameter values to run Hector through model iterations whereby parameter values are substituted (without replacement) for each model run. Hector runs can then be weighted based on fidelity to observation. 
Last, this vignette will show how to calculate probabilistic projections of future climate change using Shared Socio-economic Pathways (SSPs).

#### 

# Set-up

## Configure Hector core

First, load the `matilda` package

```{r setup}
library(matilda)
```

Next, we will initialize a "core" for a new Hector instance. 
More information about establishing a new core for running Hector can be found in the tutorial for using the [Hector R interface](https://jgcri.github.io/hector/articles/intro-to-hector.html).

```{r}
# Reading INI file with emission scenario of interest
ini <- system.file("input/hector_ssp245.ini", package = "hector")

# Creating a new core 
c_ssp245 <- newcore(ini)

```

This new Hector core is a self-contained object with information about Hector inputs and outputs.

## Generate parameter values

Now that a new Hector core is configured, we can generate parameter values. These will be subsequently used to set parameter variables when we run the Hector model.

We generate parameter values using `generate_params()`. 
This function uses parameter values from the established Hector core to set the mean of a distribution (typically normal or lognormal) for each parameter, and provides parameter standard deviations based on the science literature.
It then uses the number of `draws` (supplied by user) to generate randomly sampled values from the parameters' respective distributions.

```{r}
# Generate a data frame of random parameter values
param_values <- generate_params(c_ssp245, 10)

head(param_values)
```

We now have a data frame object called `param_values` that contains our model parameter names with 10 random values sampled for each parameter.

## Defining an output metric



# Running Hector with iterations

`iterate_hector()` will run Hector multiple times, setting new parameter values with each.

Running `iterate_hector()` requires a core, a data frame of parameter values, and a **metric** object. Metric objects contain a combination of identifiers that communicates what data is important for fetching from a Hector core. These objects are important for reducing computing time and memory by only saving the output we are interested in. For example, we can use a metric object defined as:

`Probabilistic Hector Metric:  mean global_tas 2000  to  2100`

to estimate mean global air temperature anomaly (global_tas) in years 2000-2100, for each Hector model iteration.

The `new_metric()` function can be used to define our metric.

Below we will create a metric indicating that we want to retrieve results for global average air temperature anomaly (`global_tas`) for the years 1960 to 2100. We will also specify that we are interested in computing the _mean_ of this temperature output.

It is important to note that the operation (`op`, an aggregate function) stored in our metric will **not** be used in the `iterate_hector` function, but will be important for subsequent steps in the analysis.

In this vignette we will be using observed atmospheric CO~2~ to screen Hector outputs for realism. This will be covered in detail below.

In order to screen our Hector runs based on observed CO~2~, we will need the `CO2_concentration` variable included in our Hector output. Therefore, we will include it as a desired variable when defining the metric.

```{r}
# Setting a new_metric object for Hector analysis
my_metric <- new_metric(c(GLOBAL_TAS(), CONCENTRATIONS_CO2()), 1960:2100, mean)

print(my_metric)
```

We can now use `iterate_hector` to run the model.

```{r, message=FALSE}
# Run Hector model repeatedly over all parameter values
results <- iterate_hector(core = c_ssp245, metric = my_metric, params = param_values)

head(results)
```

Viewing the full results shows global_tas and CO2_concentration values from 1960-2100 for 10 separate runs, as indicated by `run_number`.

The result is a `data.frame` and therefore we can plot the results easily in `ggplot2`.

```{r fig1, fig.align='center', fig.height=4, fig.width=6}
# plotting results from iterative Hector run
library(ggplot2)

ggplot(data = results, 
       aes(x = year, y = value, group = run_number)) +
  geom_line() +
  facet_wrap(~variable, scales = "free_y")
```

#### 

# Screening Hector results with observed data

It is important to note that Hector results should be screened to ensure that model outputs are consistent with current observations and/or future climate from Earth System Models (see e.g. [Goodwin and Cael 2021](https://esd.copernicus.org/articles/12/709/2021/)).
Similarly, here we score Hector runs based on how closely they reflect observed data; this score is then use to weight the runs in the final probabilistic calculation.

We score model runs using a scoring **criterion**. A criterion is an object that defines information used to score Hector runs. the `matilda` package provides internal criterion for easy use but also gives the user the ability to create their own scoring criterion using the `new_crit()` function. For example:

```{r}
# Create a new criteria that can be used to screen Hector runs
my_crit <- new_crit(CONCENTRATIONS_CO2(), 
                    years = metricdata_co2$year, 
                    obs_values = metricdata_co2$co2_ppm)

my_crit
```

For this example we will take advantage of an internal criterion `crit_co2_obs()`, which uses [Mauna Loa atmospheric CO~2~ observations](https://gml.noaa.gov/ccgg/trends/) to score Hector results.

We can score Hector runs with the function `score_hruns()` which uses any **scoring function** to screen the Hector results. A scoring function is a mathematical function that aims to weight model runs based on proximity to observed data.

Here, we will use the scoring function `score_ramp` which requires the user to provide additional arguments for calculating Hector run scores (`w1` and `w2`). As differences between Hector runs and observed data values are computed, runs that have differences \< `w1` will score 1.0, runs with differences \> `w2` will score 0, and runs that fall between `w1` and `w2` will produce scores between 1.0 and 0.

```{r}
# Score Hector runs with observed CO2 data
scores <- score_hruns(results, crit_co2_obs(), score_ramp, w1 = 2, w2 = 20)

scores
```

The result of scoring the Hector runs shows which model runs closely resemble values from observed data (scores close to 1), and which deviate further from observed values (scores closer to 0). These scores will be used to weight model contribution to our probabilistic projections.

We can plot our scored Hector runs highlighting which runs were closest to observed data:

```{r fig2, fig.align='center', fig.height=4, fig.width=6}
# merge results with model scores
results_scored <- merge(results, scores, by = "run_number")

ggplot(data = results_scored) +
  geom_line(aes(x = year, y = value, group = run_number, color = scores)) +
  scale_color_continuous() +
  facet_wrap(~variable, scales = "free_y")
```

Here, we can see that model runs colored in darker blue have lower scores and will have smaller influence on the overall probabilistic projections.

#### 

# Calculating metrics

With our Hector results we can also compute metric values for each run.

We can establish a new metric that will filter global_tas for years 2000-2100 from our Hector result, then we can use `metric_calc()` to compute the mean values for each run:

```{r}
# new metric for mean global_tas from 2000-2100
metric_global_tas <- new_metric(GLOBAL_TAS(), 2000:2100, mean)

# computing metric values
metric_values <- metric_calc(results, metric_global_tas)

metric_values

```

This result shows the mean global air temperature anomaly by the end of 2100 for each of our ten model runs.

#### 

# Weighted probabilistic projections

We can use the newly calculated metric values and the scored model runs to compute the likelihood of different climatic outcomes. The `prob_calc()` function allows us to group metric values into bins and calculates probabilities of each outcome, weighted by the scores of the Hector runs.

For example, we may be interested in the probability that mean global_tas will remain below 2.0$^\circ$ C by the end of 2100:

```{r}
# establishing bin limits for grouping metric values
bins <- c(0, 1, 2, 3)

# Calculating probabilities for global_tas under 2C
probabilities <- prob_calc(metric_values$metric_result, bins = bins, scores = scores$scores)

probabilities
  
```

The `prob_calc()` function bins each metric and sums the scores of each Hector run as it is binned. Then, it uses the summed score of each bin to compute the probability of of each binned outcome.

The results above show that for the ten Hector runs being used for this analysis, the likelihood that mean global air temperature anomaly will be between 2-3$^\circ$ C is higher than the likelihood that it will be less than 2$^\circ$ C by the end of the 21st century.

#### 

# Using Hector probabilistic framework to analyze climate outcomes of SSP scenarios

The Hector model runs fairly quickly, even when incorporating parameter uncertainty with many iterations. The speed makes it easy to run lots of simulations given slightly different model configurations. For example, we can explore how different shared socio-economic pathways will impact future climate projections.

The overall procedure for this is the same as presented in the previous sections.

```{r fig3, fig.align='center', fig.height=6, fig.width=8, message=FALSE, echo=FALSE}
#' Scored Hector runs
#'
#' @param inifile a path to ini file of emissions pathway
#' @param draws number of random draws to generate model parameters
#' @param metric a metric defining data to filter from Hector outpu
#' @param crit scoring criterion to use
#'
#' @return Hector results with added column scoring each run.
scored_hector_runs <- function(inifile, draws, metric, crit) {
  # iniate and core
  core = newcore(inifile)
  # generate parameters
  params = generate_params(core, draws)
  # running Hector
  h_result = iterate_hector(core, metric, params)
  # score Hector runs 
  scores = score_hruns(h_result, crit, score_ramp, w1 = 2, w2 = 20)
  # merge scores with Hector Results
  scored_hector = merge(h_result, scores, "run_number")
  # return
  return(scored_hector)  
}

# Establishing ini files for each scenario
ini_126 <- system.file("input/hector_ssp126.ini", package = "hector")
ini_245 <- system.file("input/hector_ssp245.ini", package = "hector")
ini_370 <- system.file("input/hector_ssp370.ini", package = "hector")
ini_585 <- system.file("input/hector_ssp585.ini", package = "hector")

# new metric for CO2 and global_tas
my_metric <- new_metric(c(GLOBAL_TAS(), CONCENTRATIONS_CO2()), 
                        years = 1959:2100,
                        op = mean)

# new metric for probabilities of global_tas 
metric_global_tas <- new_metric(GLOBAL_TAS(),
                                years = 1990:2100,
                                op = mean)

# Running hector for each scenario and adding column fro ssp label
hector_126 <- scored_hector_runs(ini_126, 50, my_metric, crit_co2_obs())
hector_126$ssp <- rep("ssp126")
hector_245 <- scored_hector_runs(ini_245, 50, my_metric, crit_co2_obs())
hector_245$ssp <- rep("ssp245")
hector_370 <- scored_hector_runs(ini_370, 50, my_metric, crit_co2_obs())
hector_370$ssp <- rep("ssp370")
hector_585 <- scored_hector_runs(ini_585, 50, my_metric, crit_co2_obs())
hector_585$ssp <- rep("ssp585")

# Merging hector results for plotting
hector_merge <- rbind(hector_126,
                      hector_245,
                      hector_370,
                      hector_585)

# Plotting CO2 projections
plot_co2 <- ggplot(hector_merge [hector_merge$variable 
                                 %in% "CO2_concentration", ]) +
  geom_line(aes(x = year, y = value,
                group = run_number,
                color = scores, 
                alpha = scores),
            linewidth = 1) +
  scale_color_gradient(high = "dodgerblue4", low = "lightblue1") +
  scale_alpha_continuous(range = c(0.1, 1)) +
  geom_line(data = matilda:::metricdata_co2,
            aes(year, co2_ppm),
            color = "red",
            linewdith = 1) +
  facet_wrap(~variable + ssp) +
  ylab(expression(CO[2]~Concentration~(ppm))) +
  theme_light() +
  guides(alpha = "none")

plot_co2

```

```{r fig4, fig.align='center', fig.height=3, fig.width=8, echo=FALSE}
#' Calculating probabilities 
#'
#' @param h_result A hector result
#' @param metric A metric to filter results of interest
#' @param crit A criterion used to score Hector runs
#' @param bins Bins for computing probabilities - defaults for global_tas
#'
#' @return A data frame of probabilities 
probabilities <- function(h_result,
                          metric,
                          crit,
                          bins = c(1, 1.5, 2, 3, 4, Inf)) {
  # calculating metrics
  metrics = metric_calc(h_result, metric)
  # calculating scores
  scores = score_hruns(h_result, crit, score_ramp, w1 = 2, w2 = 20)
  # merging metrics and scores
  metric_scores = merge(metrics, scores, by = "run_number")
  # calculating probability
  probability = prob_calc(metric_scores$metric_result, bins,
                          metric_scores$scores)
  # coercing probability to data frame for plotting
  probs = as.data.frame(probability)
  # return
  return(probs)
}

# Calculating probabilities for each hector run
probs_126 <- probabilities(hector_126, metric_global_tas, crit_co2_obs())
probs_126$ssp <- rep("ssp_126")
probs_245 <- probabilities(hector_245, metric_global_tas, crit_co2_obs())
probs_245$ssp <- rep("ssp_245")
probs_370 <- probabilities(hector_370, metric_global_tas, crit_co2_obs())
probs_370$ssp <- rep("ssp_370")
probs_585 <- probabilities(hector_585, metric_global_tas, crit_co2_obs())
probs_585$ssp <- rep("ssp_585")

#combining dfs with scenario types and probs
results_all <- rbind(probs_126,
                     probs_245,
                     probs_370,
                     probs_585)
colnames(results_all) <- c("Warming", "Score" ,"Probability", "Scenario")

# Plotting probabilities as stacked bar graph
ggplot(results_all, aes(fill = Warming, y = Probability, x = Scenario)) +
  geom_bar(position = position_fill(reverse = T), 
           stat = "identity",
           width = 0.6) +
  scale_y_continuous(breaks = seq(0, 1.0, 0.1)) +
  scale_fill_manual(values = c("dark grey", "light coral", "dark red", "black"),
                    labels = c("1 to 1.5 C", "1.5 to 2 C", "2 to 3 C", "3 to 4 C")) +
  coord_flip() +
  theme_light() 

```

This analysis shows how different SSP scenarios impact future CO~2~ concentration projections. The inclusion of a probabilistic framework with parameter uncertainty provides the capability to establish a "cone of uncertainty" for possible futures under each pathway (top panel). These possible futures are weighted by how well the model runs resulting in each projection align with observed data (darker blue indicating a better fit to historic data). 

We can also use the functions in `matilda` to calculate and plot the likelihood of projected warming until 2100 (bottom panel). We can see from this analysis that the likelihood of remaining below 2.0$^\circ$ C becomes less likely as the SSP is changed from sustainable (SSP1-2.6) to fossil-fuel development (SSP5-8.5).
