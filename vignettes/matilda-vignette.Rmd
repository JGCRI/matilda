---
title: "matilda-vignette"
output: 
  rmarkdown::html_vignette:
    toc: true
    tocdepth: 2
vignette: >
  %\VignetteIndexEntry{matilda-vignette}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)
```

# Introduction

`matilda` is a package that provides a probabilistic framework to the Hector simple climate model. 
This vignette works through the basic functionality of `matilda`. 
First, it shows how to generate a random sample of important model parameters from arbitrary (most commonly, normal or lognormal) distributions. 
It then shows how to run Hector using the generated parameters, score model outputs for realism, and compute probabilities of climate variable projections.
Finally, this vignette will show how to calculate probabilistic projections of future climate change using Shared Socio-economic Pathways (SSPs).

#### 

# Set-up

## Configure Hector core

First, load the `matilda` package

```{r setup}
library(matilda)
```

Next, we will initialize a "core" for a new Hector instance. 
More information about establishing a new core for running Hector can be found in the tutorial for using the [Hector R interface](https://jgcri.github.io/hector/articles/intro-to-hector.html).

```{r}
# Read INI file with emission scenario of interest and create a new core
ini <- system.file("input/hector_ssp245.ini", package = "hector")
c_ssp245 <- newcore(ini)
```

This new Hector core is a self-contained object with information about Hector inputs and outputs.

## Generate parameter values

We generate parameter values using `generate_params()`. 
This function uses parameter values from the established Hector core to set the mean of a distribution (typically normal or lognormal) for each parameter, and provides parameter standard deviations based on the science literature.
It then uses the number of `draws` (supplied by the user) to generate randomly sampled values from the parameters' respective distributions.

```{r}
# Generate a data frame of random parameter values
set.seed(1)
param_values <- generate_params(c_ssp245, draws = 10)
print(param_values)
```

We now have a data frame object with 10 random values sampled for each parameter.

It may be of interest to the user to only apply changes to a few model parameters while keeping the other static. We can easily enforce this type of control by manipulating which columns in our `param_values` data frame. For example, if we are only interested in perturbing CO~2~ fertilization and ocean heat diffusivity (parameters `BETA()` and `DIFFUSIVITY()`, respectively), we can simply drop all other columns in the `param_values` data frame.

```{r}
# producing data frame to only manipulate the BETA parameter
alter_beta_diff <- param_values[c(1, 5)]

print(alter_beta_diff)
```

In these cases, only the parameters included in the subsetted data frame will be altered during Hector runs. All other parameters will follow Hector defaults.

# Running Hector iteratively

The `iterate_model()` runs Hector multiple times, setting new parameter values with each iteration, and combining the results for easy analysis.

Running `iterate_model()` requires a Hector core and a data frame of parameter values.

```{r, message=FALSE}
# Run Hector repeatedly over all parameter values
results <- iterate_model(
  core = c_ssp245,
  params = param_values
)
head(results)
```

The resulting data frame has `r nrow(results)` rows: 10 samples * 556 years * 4 variables; i.e., it returns 10 separate runs (as indicated by `run_number`) for the major climate variables of a Hector output for the years `1745:2300`.

We can plot the results easily in `ggplot2`.

```{r fig1, fig.align='center', fig.height=4, fig.width=6}
library(ggplot2)

ggplot(
  data = results,
  aes(x = year, y = value, group = run_number)
) +
  geom_line() +
  facet_wrap(~variable, scales = "free_y")
```

#### 

# Screening Hector results

Before further analysis, we frequently want to score the model results against current observations and/or future climate from Earth System Models (see e.g. [Goodwin and Cael 2021](https://esd.copernicus.org/articles/12/709/2021/)).
This score is then used to weight the runs in the final probabilistic calculation.

Scoring Hector runs requires a **scoring criterion**. Scoring criterion are objects used to aid in scoring model runs. The criterion defines information that can be filtered from the Hector result and used to score Hector runs against observations. The `matilda` package provides several pre-defined criteria for easy use, but also gives the user the ability to create their own arbitrary criteria using the `new_criterion()` function. For example:

```{r}
# Create a new criterion that can be used to screen Hector runs
# In this case, we set up a global temperature criterion, with the 'observations'
# running from 1951 to 2000
my_criterion <- new_criterion(GLOBAL_TAS(),
  years = 1951:2000,
  obs_values = seq(0.4, 1.0, length.out = 50)
)

my_criterion
```

For this example we will take advantage of an internal criterion - `criterion_co2_obs()`, which uses [Mauna Loa atmospheric CO~2~ observations](https://gml.noaa.gov/ccgg/trends/) to score Hector results.

We can score Hector runs with the function `score_runs()` which uses any **scoring function** to screen Hector results. A scoring function is a mathematical function that weights model realizations based on proximity to observed dat (i.e., to a criterion).

Here we use a `matilda`-provided scoring function called `score_ramp` that linearly ramps down a model run's score as it gets farther away from observations: specifically, model runs with differences $\le$ the `w1` parameter will score 1.0, while runs with differences $\ge$ `w2` will score 0.0, and model run scores decrease linearly from `w1` to `w2`.

```{r}
# Score Hector runs with observed CO2 data
scores <- score_runs(results, criterion_co2_obs(), score_ramp, w1 = 2, w2 = 20)

scores
```

The result of scored Hector runs shows which model runs closely resemble values from observed data (scores close to 1), and which deviate further from observed values (scores closer to 0). These scores will be used to weight model contribution to probabilistic projections.

We can plot our scored Hector runs highlighting which runs were closest to observed data:

```{r fig2, fig.align='center', fig.height=4, fig.width=6}
# Merge results with model scores
results_scored <- merge(results, scores, by = "run_number")

ggplot(data = results_scored) +
  geom_line(aes(x = year, y = value, group = run_number, color = weights)) +
  scale_color_continuous() +
  facet_wrap(~variable, scales = "free_y")
```

Here, we can see that model runs colored in darker blue have lower scores and will have smaller influence on the final probabilistic projections.

#### 

# Defining and calculating output metrics

**Metric objects** define what data the user is most interested in from a Hector core. For example, we can use a metric object defined as:

`Probabilistic Hector Metric:  mean global_tas 2000  to  2100`

to estimate mean global air temperature anomaly (`global_tas`) in years 2000-2100 from each Hector model iteration.

The `new_metric()` function can be used to define any arbitrary metric.

We create a metric indicating that we want to filter the Hector results to include global average air temperature anomaly (`global_tas`) for the years 2000 to 2100. We also specify that we are interested in computing the _mean_ of the temperature for these years

```{r}
# Define a new_metric object for Hector analysis
my_metric <- new_metric(GLOBAL_TAS(), 2000:2100, mean)

print(my_metric)
```

After defining a new metric of interest, we can use `metric_calc()` to compute metric values for each run:

```{r}
# Compute metric values
metric_values <- metric_calc(results, my_metric)

metric_values
```

This result shows the mean global air temperature anomaly by the end of 2100 for each of our ten model runs.

#### 

# Weighted probabilistic projections

We now have the (1) calculated metric values and (2) scored model runs, and so can compute the likelihood of different climatic outcomes. The `prob_calc()` function allows the user to group metric values into bins and calculates probabilities of each outcome, weighted by the scores of the Hector runs.

For example, we may be interested in the probability that mean `global_tas` will remain below 2.0$^\circ$ C by the end of 2100:

```{r}
# Establish bin limits for grouping metric values
bins <- c(0, 1, 2, 3)

# Calculate probabilities for global_tas under 2C
prob_calc(metric_values$metric_result,
  bins = bins,
  scores = scores$weights
)
```

The `prob_calc()` function bins each metric and sums the scores of each Hector run as it is binned. Then, it uses the summed score of each bin to compute the probability of each climate variable outcome.

The output above shows the likelihood that the mean rise in global air temperature anomaly will fall within each of the temperature ranges we defined (0-1$^\circ$ C, 1-2$^\circ$ C, and 2-3$^\circ$ C) by the end of the 21st century, when we use our weighted Hector simulations to compute temperature probabilities.

#### 

# Using Hector probabilistic framework to analyze climate outcomes of SSP scenarios

The Hector model runs fairly quickly, even when incorporating parameter uncertainty with many iterations. The speed makes it easy to run lots of simulations given slightly different model configurations. For example, we can explore how different shared socio-economic pathways will impact future climate projections.

The overall procedure for this example is the same as presented in the previous sections. The results presented below show each of four SSP scenarios (SSP1-2.6, SSP2-4.5, SSP3-7.0, and SSP5-8.5) as they are run through Hector with 50 parameter iterations. The Hector model realizations were scored using observed CO~2~ concentrations. We plot simulated CO~2~ concentration pathways (top panel) and probabilities of warming (bottom panel) from 1990 until the end of the 21st century.   

```{r fig3, fig.align='center', fig.height=8, fig.width=8, message=FALSE, echo=FALSE}
#' Scored Hector runs
#'
#' @param inifile a path to ini file of emissions pathway
#' @param draws number of random draws to generate model parameters
#' @param metric a metric defining data to filter from Hector output
#' @param crit scoring criterion to use
#' @param ssp_name An optional name to identify the core (string)
#'
#' @return Hector results with added column scoring each run.
scored_hector_runs <- function(inifile, ssp_name, draws, crit) {
  # initiate and core
  core <- newcore(inifile, name = ssp_name)
  # generate parameters
  params <- generate_params(core, draws)
  # running Hector
  h_result <- iterate_model(core, params)
  # score Hector runs
  scores <- score_runs(h_result, crit, score_ramp, w1 = 2, w2 = 20)
  # merge scores with Hector Results
  scored_hector <- merge(h_result, scores, "run_number")
  # return
  return(scored_hector)
}

# Establishing ini files for each scenario
ini_126 <- system.file("input/hector_ssp126.ini", package = "hector")
ini_245 <- system.file("input/hector_ssp245.ini", package = "hector")
ini_370 <- system.file("input/hector_ssp370.ini", package = "hector")
ini_585 <- system.file("input/hector_ssp585.ini", package = "hector")

# Running hector for each scenario
set.seed(1)
hector_126 <- scored_hector_runs(ini_126, ssp_name = "ssp126", 20, criterion_co2_obs())
hector_245 <- scored_hector_runs(ini_245, ssp_name = "ssp245", 20, criterion_co2_obs())
hector_370 <- scored_hector_runs(ini_370, ssp_name = "ssp370", 20, criterion_co2_obs())
hector_585 <- scored_hector_runs(ini_585, ssp_name = "ssp585", 20, criterion_co2_obs())

# Merging hector results for plotting
hector_merge <- rbind(
  hector_126,
  hector_245,
  hector_370,
  hector_585
)

# Plotting CO2 projections
plot_co2 <- ggplot(subset(
  hector_merge,
  year > 1990 & year < 2100 &
    variable == CONCENTRATIONS_CO2()
)) +
  geom_line(
    aes(
      x = year, y = value,
      group = run_number,
      color = weights,
      alpha = weights
    ),
    linewidth = 1
  ) +
  scale_color_gradient(high = "dodgerblue4", low = "lightblue1") +
  scale_alpha_continuous(range = c(0.1, 1)) +
  geom_line(
    data = matilda:::observed_data_co2,
    aes(year, co2_ppm),
    color = "red",
    linewidth = 1
  ) +
  facet_wrap(~ variable + scenario) +
  ylab(expression(CO[2] ~ Concentration ~ (ppm))) +
  theme_light() +
  guides(alpha = "none")

plot_co2
```

```{r fig4, fig.align='center', fig.height=3, fig.width=8, echo=FALSE}
#' Calculating probabilities
#'
#' @param h_result A hector result
#' @param metric A metric to filter results of interest
#' @param criterionA criterion used to score Hector runs
#' @param bins Bins for computing probabilities - defaults for global_tas
#'
#' @return A data frame of probabilities
probabilities <- function(h_result,
                          metric,
                          crit,
                          bins = c(1, 1.5, 2, 3, 4, Inf)) {
  # calculating metrics
  metrics <- metric_calc(h_result, metric)
  # calculating scores
  scores <- score_runs(h_result, crit, score_ramp, w1 = 2, w2 = 20)
  # merging metrics and scores
  metric_scores <- merge(metrics, scores, by = "run_number")
  # calculating probability
  probability <- prob_calc(
    metric_scores$metric_result, bins,
    metric_scores$weights
  )
  # coercing probability to data frame for plotting
  probs <- as.data.frame(probability)
  # return
  return(probs)
}

# defining metric of mean global_tas for 1990:2100
metric_global_tas <- new_metric(GLOBAL_TAS(), years = 1990:2100, op = mean)

# Calculating probabilities for each hector run
probs_126 <- probabilities(hector_126, metric_global_tas, criterion_co2_obs())
probs_126$scenario <- rep("ssp_126")
probs_245 <- probabilities(hector_245, metric_global_tas, criterion_co2_obs())
probs_245$scenario <- rep("ssp_245")
probs_370 <- probabilities(hector_370, metric_global_tas, criterion_co2_obs())
probs_370$scenario <- rep("ssp_370")
probs_585 <- probabilities(hector_585, metric_global_tas, criterion_co2_obs())
probs_585$scenario <- rep("ssp_585")

# combining dfs with scenario types and probs
results_all <- rbind(
  probs_126,
  probs_245,
  probs_370,
  probs_585
)
colnames(results_all) <- c("Warming", "Score", "Probability", "Scenario")

# Plotting probabilities as stacked bar graph
ggplot(results_all, aes(fill = Warming, y = Probability, x = Scenario)) +
  geom_bar(
    position = position_fill(reverse = T),
    stat = "identity",
    width = 0.6
  ) +
  scale_y_continuous(breaks = seq(0, 1.0, 0.1)) +
  scale_fill_manual(
    values = c("dark grey", "light coral", "dark red", "black"),
    labels = c("1 to 1.5 C", "1.5 to 2 C", "2 to 3 C", "3 to 4 C")
  ) +
  coord_flip() +
  theme_light()
```

This analysis shows how different SSP scenarios impact future CO~2~ concentration projections. The inclusion of a probabilistic framework with parameter uncertainty provides the capability to establish a "cone of uncertainty" for possible futures under each pathway (top panel). These possible futures are weighted by how well the model runs resulting in each projection align with observed data (darker blue indicating a better fit to historic data). 

We can also use the functions in `matilda` to calculate and plot the likelihood of projected warming until 2100 (bottom panel). We can see from this analysis that the likelihood of remaining below 2.0$^\circ$ C becomes less likely as the SSP is changed from sustainable (SSP1-2.6) to fossil-fuel development (SSP5-8.5).

####
